# æ¨¡æ“¬äººé¡è¡Œç‚ºçš„çˆ¬èŸ²è¨­è¨ˆæŒ‡å—

å°ˆæ¥­çˆ¬èŸ²å¯¦ä½œç¶“é©—æ•´ç†ï¼Œé©ç”¨æ–¼è¨­è¨ˆæ›´å¤šé¿å… APIã€æ¨¡æ“¬äººé¡è¡Œç‚ºçš„çˆ¬èŸ²å·¥å…·ï¼Œä»¥ Trading Economics ç‚ºä¾‹ã€‚

---

## ç›®éŒ„

1. [æ ¸å¿ƒæ¶æ§‹](#æ ¸å¿ƒæ¶æ§‹)
2. [æŠ€è¡“æ£§é¸æ“‡](#æŠ€è¡“æ£§é¸æ“‡)
3. [é˜²åµæ¸¬ç­–ç•¥](#é˜²åµæ¸¬ç­–ç•¥)
4. [å®Œæ•´å¯¦ä½œæµç¨‹](#å®Œæ•´å¯¦ä½œæµç¨‹)
5. [ç¨‹å¼ç¢¼æ¨¡æ¿](#ç¨‹å¼ç¢¼æ¨¡æ¿)
6. [å¸¸è¦‹å•é¡Œè™•ç†](#å¸¸è¦‹å•é¡Œè™•ç†)

---

## æ ¸å¿ƒæ¶æ§‹

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     çˆ¬èŸ²æµç¨‹ç¸½è¦½                              â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                                              â”‚
â”‚  1. è«‹æ±‚å‰æº–å‚™                                               â”‚
â”‚     â”œâ”€ éš¨æ©Ÿå»¶é² (0.5-2 ç§’)                                  â”‚
â”‚     â”œâ”€ éš¨æ©Ÿé¸æ“‡ User-Agent                                  â”‚
â”‚     â””â”€ é…ç½®ç€è¦½å™¨é¸é … (ç§»é™¤è‡ªå‹•åŒ–æ¨™è¨˜)                       â”‚
â”‚                                                              â”‚
â”‚  2. é é¢æŠ“å– (Selenium)                                      â”‚
â”‚     â”œâ”€ å•Ÿå‹• Chrome (headless)                               â”‚
â”‚     â”œâ”€ è¼‰å…¥ç›®æ¨™ URL                                         â”‚
â”‚     â”œâ”€ ç­‰å¾…å‹•æ…‹å…§å®¹è¼‰å…¥ (WebDriverWait)                     â”‚
â”‚     â”œâ”€ é¡å¤–ç­‰å¾… JS åŸ·è¡Œ (3 ç§’)                              â”‚
â”‚     â””â”€ å–å¾—å®Œæ•´ HTML                                        â”‚
â”‚                                                              â”‚
â”‚  3. å…§å®¹è§£æ (BeautifulSoup)                                â”‚
â”‚     â”œâ”€ å¤šå±¤å‚™ç”¨é¸æ“‡å™¨ç­–ç•¥                                   â”‚
â”‚     â”œâ”€ æå–ç›®æ¨™è³‡æ–™                                         â”‚
â”‚     â””â”€ å¤±æ•—æ™‚ä¿å­˜ debug HTML                                â”‚
â”‚                                                              â”‚
â”‚  4. è³‡æ–™è™•ç†èˆ‡å„²å­˜                                           â”‚
â”‚     â”œâ”€ è³‡æ–™æ˜ å°„/åˆ†é¡                                        â”‚
â”‚     â”œâ”€ é‡è¤‡æª¢æ¸¬                                             â”‚
â”‚     â””â”€ æŒä¹…åŒ–å„²å­˜                                           â”‚
â”‚                                                              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## æŠ€è¡“æ£§é¸æ“‡

### å¿…è¦å¥—ä»¶

```bash
pip install selenium webdriver-manager beautifulsoup4 lxml loguru
```

| å¥—ä»¶                | ç”¨é€”              | èªªæ˜                            |
|---------------------|-------------------|---------------------------------|
| `selenium`          | ç€è¦½å™¨è‡ªå‹•åŒ–      | åŸ·è¡Œ JavaScriptã€æ¨¡æ“¬çœŸå¯¦ç€è¦½å™¨ |
| `webdriver-manager` | ChromeDriver ç®¡ç† | è‡ªå‹•ä¸‹è¼‰åŒ¹é…ç‰ˆæœ¬çš„ driver       |
| `beautifulsoup4`    | HTML è§£æ         | ç°¡å–®æ˜“ç”¨çš„ DOM æ“ä½œ             |
| `lxml`              | è§£æå™¨            | é«˜æ•ˆèƒ½ã€å®¹éŒ¯èƒ½åŠ›å¼·              |
| `loguru`            | æ—¥èªŒ              | æ–¹ä¾¿èª¿è©¦                        |

### ç‚ºä½•é¸æ“‡ Selenium è€Œé requests/httpxï¼Ÿ

| æ–¹æ¡ˆ           | å„ªé»                                | ç¼ºé»                  | é©ç”¨å ´æ™¯              |
|----------------|-------------------------------------|-----------------------|-----------------------|
| **Selenium**   | åŸ·è¡Œ JSã€æ¨¡æ“¬çœŸå¯¦ç€è¦½å™¨ã€ç¹éåçˆ¬èŸ² | è³‡æºæ¶ˆè€—å¤§ã€é€Ÿåº¦è¼ƒæ…¢  | **å‹•æ…‹ç¶²ç«™ã€JS æ¸²æŸ“** |
| requests/httpx | è¼•é‡ã€å¿«é€Ÿ                          | ç„¡æ³•åŸ·è¡Œ JSã€æ˜“è¢«åµæ¸¬ | éœæ…‹ HTML ç¶²ç«™        |
| Playwright     | ç¾ä»£åŒ–ã€æ›´å¥½çš„ API                  | å­¸ç¿’æ›²ç·š              | éœ€è¦æ›´å¤šç€è¦½å™¨æ”¯æ´    |

---

## é˜²åµæ¸¬ç­–ç•¥

### 1. Chrome é¸é …é…ç½®

```python
from selenium import webdriver
from selenium.webdriver.chrome.options import Options

chrome_options = Options()

# åŸºæœ¬è¨­å®š
chrome_options.add_argument('--headless')               # ç„¡é ­æ¨¡å¼
chrome_options.add_argument('--no-sandbox')             # Linux/Docker ç›¸å®¹
chrome_options.add_argument('--disable-dev-shm-usage')  # é¿å…è¨˜æ†¶é«”å•é¡Œ
chrome_options.add_argument('--disable-gpu')            # headless å»ºè­°é—œé–‰

# ğŸ”´ æ ¸å¿ƒé˜²åµæ¸¬è¨­å®š
chrome_options.add_argument('--disable-blink-features=AutomationControlled')  # ç§»é™¤ navigator.webdriver æ¨™è¨˜
chrome_options.add_experimental_option('excludeSwitches', ['enable-automation'])  # ç§»é™¤è‡ªå‹•åŒ–æç¤º
chrome_options.add_experimental_option('useAutomationExtension', False)  # ç¦ç”¨è‡ªå‹•åŒ–æ“´å±•
```

### 2. User-Agent è¼ªæ›

```python
import random

USER_AGENTS = [
    # Windows Chrome
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    # macOS Chrome
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    # Windows Firefox
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',
    # macOS Safari
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/605.1.15 (KHTML, like Gecko) Version/17.1 Safari/605.1.15',
    # Linux Chrome
    'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
]

# æ¯æ¬¡è«‹æ±‚éš¨æ©Ÿé¸æ“‡
user_agent = random.choice(USER_AGENTS)
chrome_options.add_argument(f'user-agent={user_agent}')
```

### 3. éš¨æ©Ÿå»¶é²

```python
import asyncio
import random

# è«‹æ±‚å‰éš¨æ©Ÿå»¶é² (æ¨¡æ“¬äººé¡æ€è€ƒæ™‚é–“)
delay = random.uniform(0.5, 2.0)
await asyncio.sleep(delay)
```

### 4. å®šæ™‚ä»»å‹™åŠ å…¥ Jitter

```python
from apscheduler.schedulers.asyncio import AsyncIOScheduler
from apscheduler.triggers.interval import IntervalTrigger

scheduler = AsyncIOScheduler()

# æ¯ 5 åˆ†é˜åŸ·è¡Œï¼ŒÂ±15 ç§’éš¨æ©Ÿåç§»
scheduler.add_job(
    crawl_function,
    trigger=IntervalTrigger(minutes=5, jitter=15),
    id='crawler_job'
)
```

### é˜²åµæ¸¬ç­–ç•¥ç¸½çµ

| ç­–ç•¥                       | æ•ˆæœ               | å„ªå…ˆç´š  |
|----------------------------|--------------------|---------|
| ç§»é™¤ `navigator.webdriver` | æ ¸å¿ƒï¼Œé˜²æ­¢ JS åµæ¸¬ | ğŸ”´ å¿…è¦ |
| éš¨æ©Ÿ User-Agent            | é¿å…å›ºå®š UA è¢«è­˜åˆ¥ | ğŸ”´ å¿…è¦ |
| è«‹æ±‚å‰éš¨æ©Ÿå»¶é²             | æ¨¡æ“¬äººé¡è¡Œç‚º       | ğŸ”´ å¿…è¦ |
| ç¦ç”¨è‡ªå‹•åŒ–æ“´å±•             | ç§»é™¤ Chrome ç—•è·¡   | ğŸŸ¡ å»ºè­° |
| å®šæ™‚ä»»å‹™ Jitter            | é¿å…å›ºå®šé–“éš”       | ğŸŸ¡ å»ºè­° |

---

## å®Œæ•´å¯¦ä½œæµç¨‹

### æ­¥é©Ÿ 1ï¼šå»ºç«‹é…ç½®é¡

```python
# config.py
from dataclasses import dataclass
from typing import Optional
import os

@dataclass
class CrawlerConfig:
    """çˆ¬èŸ²é…ç½®"""
    target_url: str                           # ç›®æ¨™ URL
    crawl_interval_minutes: int = 5           # çˆ¬å–é–“éš” (åˆ†é˜)
    interval_jitter_seconds: int = 15         # éš¨æ©Ÿåç§» (ç§’)
    output_dir: str = 'data'                  # è¼¸å‡ºç›®éŒ„
    enabled: bool = True                      # æ˜¯å¦å•Ÿç”¨

    @classmethod
    def from_env(cls) -> 'CrawlerConfig':
        """å¾ç’°å¢ƒè®Šæ•¸è¼‰å…¥é…ç½®"""
        return cls(
            target_url=os.getenv('CRAWLER_URL', ''),
            crawl_interval_minutes=int(os.getenv('CRAWLER_INTERVAL', '5')),
            interval_jitter_seconds=int(os.getenv('CRAWLER_JITTER', '15')),
            output_dir=os.getenv('CRAWLER_OUTPUT_DIR', 'data'),
            enabled=os.getenv('CRAWLER_ENABLED', 'true').lower() == 'true'
        )
```

### æ­¥é©Ÿ 2ï¼šå»ºç«‹çˆ¬èŸ²æ ¸å¿ƒé¡

```python
# crawler.py
from typing import Optional, List, Dict
import random
import asyncio
import time

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
from loguru import logger

from config import CrawlerConfig

USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36...',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36...',
    # ... æ›´å¤š UA
]


class BaseCrawler:
    """çˆ¬èŸ²åŸºç¤é¡"""

    def __init__(self, config: CrawlerConfig):
        self.config = config
        logger.info(f"çˆ¬èŸ²åˆå§‹åŒ–å®Œæˆ: {config.target_url}")

    async def fetch_page(self) -> Optional[str]:
        """æŠ“å–é é¢ (éåŒæ­¥åŒ…è£)"""
        # éš¨æ©Ÿå»¶é²
        delay = random.uniform(0.5, 2.0)
        logger.debug(f"è«‹æ±‚å‰å»¶é² {delay:.2f} ç§’")
        await asyncio.sleep(delay)

        # åœ¨ç¨ç«‹åŸ·è¡Œç·’åŸ·è¡Œ Selenium (é¿å…é˜»å¡äº‹ä»¶å¾ªç’°)
        return await asyncio.to_thread(self._fetch_page_sync)

    def _fetch_page_sync(self) -> Optional[str]:
        """åŒæ­¥çš„ Selenium æ“ä½œ"""
        driver = None
        try:
            # é…ç½® Chrome
            chrome_options = Options()
            chrome_options.add_argument('--headless')
            chrome_options.add_argument('--no-sandbox')
            chrome_options.add_argument('--disable-dev-shm-usage')
            chrome_options.add_argument('--disable-gpu')
            chrome_options.add_argument('--disable-blink-features=AutomationControlled')
            chrome_options.add_experimental_option('excludeSwitches', ['enable-automation'])
            chrome_options.add_experimental_option('useAutomationExtension', False)

            # éš¨æ©Ÿ UA
            user_agent = random.choice(USER_AGENTS)
            chrome_options.add_argument(f'user-agent={user_agent}')

            # å•Ÿå‹•ç€è¦½å™¨
            service = Service(ChromeDriverManager().install())
            driver = webdriver.Chrome(service=service, options=chrome_options)
            driver.set_page_load_timeout(60)

            # è¼‰å…¥é é¢
            logger.info(f"æ­£åœ¨æŠ“å–: {self.config.target_url}")
            driver.get(self.config.target_url)

            # ç­‰å¾…é é¢è¼‰å…¥ (å­é¡å¯è¦†å¯«æ­¤æ–¹æ³•)
            self._wait_for_page_load(driver)

            # é¡å¤–ç­‰å¾… JS åŸ·è¡Œ
            time.sleep(3)

            return driver.page_source

        except Exception as e:
            logger.error(f"æŠ“å–å¤±æ•—: {e}")
            return None

        finally:
            if driver:
                driver.quit()

    def _wait_for_page_load(self, driver):
        """ç­‰å¾…é é¢è¼‰å…¥ (å­é¡å¯è¦†å¯«)"""
        wait = WebDriverWait(driver, 20)

        # é è¨­ç­‰å¾… body è¼‰å…¥
        try:
            wait.until(EC.presence_of_element_located((By.TAG_NAME, "body")))
        except:
            logger.warning("ç­‰å¾…é é¢è¼‰å…¥è¶…æ™‚")

    def parse(self, html: str) -> List[Dict]:
        """è§£æ HTML (å­é¡å¿…é ˆå¯¦ä½œ)"""
        raise NotImplementedError("å­é¡å¿…é ˆå¯¦ä½œ parse æ–¹æ³•")

    async def crawl(self) -> List[Dict]:
        """åŸ·è¡Œå®Œæ•´çˆ¬å–æµç¨‹"""
        # 1. æŠ“å–
        html = await self.fetch_page()
        if not html:
            return []

        # 2. è§£æ
        data = self.parse(html)

        # 3. å¾Œè™•ç† (å­é¡å¯è¦†å¯«)
        return await self.post_process(data)

    async def post_process(self, data: List[Dict]) -> List[Dict]:
        """å¾Œè™•ç† (å­é¡å¯è¦†å¯«)"""
        return data
```

### æ­¥é©Ÿ 3ï¼šå»ºç«‹ç‰¹å®šç¶²ç«™çˆ¬èŸ²

```python
# example_crawler.py
from typing import List, Dict
from bs4 import BeautifulSoup
from loguru import logger

from crawler import BaseCrawler


class ExampleSiteCrawler(BaseCrawler):
    """ç¯„ä¾‹ç¶²ç«™çˆ¬èŸ²"""

    def _wait_for_page_load(self, driver):
        """è¦†å¯«ç­‰å¾…é‚è¼¯"""
        from selenium.webdriver.common.by import By
        from selenium.webdriver.support.ui import WebDriverWait
        from selenium.webdriver.support import expected_conditions as EC

        wait = WebDriverWait(driver, 20)

        # å˜—è©¦å¤šå€‹å¯èƒ½çš„é¸æ“‡å™¨
        selectors = [
            (By.CLASS_NAME, "main-content"),
            (By.ID, "content"),
            (By.TAG_NAME, "article"),
        ]

        for by, value in selectors:
            try:
                wait.until(EC.presence_of_element_located((by, value)))
                logger.info(f"é é¢å·²è¼‰å…¥ (æ‰¾åˆ°: {value})")
                return
            except:
                continue

        logger.warning("æœªæ‰¾åˆ°é æœŸå…ƒç´ ï¼Œç¹¼çºŒè™•ç†")

    def parse(self, html: str) -> List[Dict]:
        """è§£æ HTML"""
        soup = BeautifulSoup(html, 'lxml')
        results = []

        # ğŸ”´ å¤šå±¤å‚™ç”¨é¸æ“‡å™¨ç­–ç•¥
        items = []

        # ç¬¬ä¸€å„ªå…ˆ
        items = soup.select('div.item-class')
        if items:
            logger.info(f"ä½¿ç”¨é¸æ“‡å™¨ 'div.item-class' æ‰¾åˆ° {len(items)} é …")

        # å‚™ç”¨ 1
        if not items:
            items = soup.select('article.post')
            if items:
                logger.info(f"ä½¿ç”¨å‚™ç”¨é¸æ“‡å™¨ 'article.post' æ‰¾åˆ° {len(items)} é …")

        # å‚™ç”¨ 2
        if not items:
            items = soup.select('li.list-item')
            if items:
                logger.info(f"ä½¿ç”¨å‚™ç”¨é¸æ“‡å™¨ 'li.list-item' æ‰¾åˆ° {len(items)} é …")

        # å…¨éƒ¨å¤±æ•— -> ä¿å­˜ debug HTML
        if not items:
            logger.warning("æ‰€æœ‰é¸æ“‡å™¨éƒ½å¤±æ•—")
            self._save_debug_html(html)
            return results

        # è§£ææ¯å€‹é …ç›®
        for item in items:
            try:
                title = item.select_one('h2, .title')
                content = item.select_one('p, .content')

                if title:
                    results.append({
                        'title': title.get_text(strip=True),
                        'content': content.get_text(strip=True) if content else ''
                    })
            except Exception as e:
                logger.warning(f"è§£æé …ç›®å¤±æ•—: {e}")
                continue

        return results

    def _save_debug_html(self, html: str):
        """ä¿å­˜ debug HTML"""
        try:
            with open('debug_page.html', 'w', encoding='utf-8') as f:
                f.write(html)
            logger.warning("å·²ä¿å­˜ debug_page.htmlï¼Œè«‹æ‰‹å‹•æª¢æŸ¥é¸æ“‡å™¨")
        except Exception as e:
            logger.error(f"ä¿å­˜ debug æª”æ¡ˆå¤±æ•—: {e}")
```

### æ­¥é©Ÿ 4ï¼šä½¿ç”¨çˆ¬èŸ²

```python
# main.py
import asyncio
from config import CrawlerConfig
from example_crawler import ExampleSiteCrawler


async def main():
    config = CrawlerConfig(
        target_url='https://example.com/news',
        crawl_interval_minutes=5
    )

    crawler = ExampleSiteCrawler(config)
    results = await crawler.crawl()

    for item in results:
        print(f"æ¨™é¡Œ: {item['title']}")
        print(f"å…§å®¹: {item['content'][:100]}...")
        print("-" * 50)


if __name__ == "__main__":
    asyncio.run(main())
```

---

## ç¨‹å¼ç¢¼æ¨¡æ¿

### å¿«é€Ÿé–‹å§‹æ¨¡æ¿

```python
#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
é€šç”¨çˆ¬èŸ²æ¨¡æ¿
ç”¨æ³•: ä¿®æ”¹ TARGET_URL å’Œ parse() æ–¹æ³•ä¸­çš„é¸æ“‡å™¨
"""

import asyncio
import random
import time
from typing import Optional, List, Dict

from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup

# ========== é…ç½®å€åŸŸ (ä¿®æ”¹é€™è£¡) ==========
TARGET_URL = 'https://example.com/page'
WAIT_SELECTOR = (By.CLASS_NAME, 'content')  # ç­‰å¾…æ­¤å…ƒç´ å‡ºç¾
ITEM_SELECTOR = 'div.item'                   # é …ç›®é¸æ“‡å™¨
TITLE_SELECTOR = 'h2'                        # æ¨™é¡Œé¸æ“‡å™¨
CONTENT_SELECTOR = 'p'                       # å…§å®¹é¸æ“‡å™¨
# =========================================

USER_AGENTS = [
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
    'Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:121.0) Gecko/20100101 Firefox/121.0',
]


async def fetch_page() -> Optional[str]:
    """æŠ“å–é é¢"""
    # éš¨æ©Ÿå»¶é²
    await asyncio.sleep(random.uniform(0.5, 2.0))
    return await asyncio.to_thread(_fetch_sync)


def _fetch_sync() -> Optional[str]:
    """åŒæ­¥æŠ“å–"""
    driver = None
    try:
        # Chrome é…ç½®
        options = Options()
        options.add_argument('--headless')
        options.add_argument('--no-sandbox')
        options.add_argument('--disable-dev-shm-usage')
        options.add_argument('--disable-blink-features=AutomationControlled')
        options.add_experimental_option('excludeSwitches', ['enable-automation'])
        options.add_argument(f'user-agent={random.choice(USER_AGENTS)}')

        # å•Ÿå‹•
        service = Service(ChromeDriverManager().install())
        driver = webdriver.Chrome(service=service, options=options)
        driver.set_page_load_timeout(60)

        # è¼‰å…¥
        driver.get(TARGET_URL)

        # ç­‰å¾…
        WebDriverWait(driver, 20).until(
            EC.presence_of_element_located(WAIT_SELECTOR)
        )
        time.sleep(3)

        return driver.page_source

    except Exception as e:
        print(f"æŠ“å–å¤±æ•—: {e}")
        return None

    finally:
        if driver:
            driver.quit()


def parse(html: str) -> List[Dict]:
    """è§£æ HTML"""
    soup = BeautifulSoup(html, 'lxml')
    results = []

    items = soup.select(ITEM_SELECTOR)
    for item in items:
        title = item.select_one(TITLE_SELECTOR)
        content = item.select_one(CONTENT_SELECTOR)

        if title:
            results.append({
                'title': title.get_text(strip=True),
                'content': content.get_text(strip=True) if content else ''
            })

    return results


async def main():
    html = await fetch_page()
    if html:
        data = parse(html)
        for item in data:
            print(f"æ¨™é¡Œ: {item['title']}")
            print(f"å…§å®¹: {item['content'][:100]}...")
            print("-" * 50)


if __name__ == "__main__":
    asyncio.run(main())
```

---

## å¸¸è¦‹å•é¡Œè™•ç†

### å•é¡Œ 1ï¼šé é¢è¼‰å…¥ä¸å®Œæ•´

**ç—‡ç‹€**: æŠ“åˆ°çš„ HTML å…§å®¹ç‚ºç©ºæˆ–ä¸å®Œæ•´

**è§£æ±ºæ–¹æ¡ˆ**:
```python
# 1. å¢åŠ ç­‰å¾…æ™‚é–“
time.sleep(5)  # å¾ 3 ç§’å¢åŠ åˆ° 5 ç§’

# 2. ç­‰å¾…ç‰¹å®šå…ƒç´ 
wait.until(EC.presence_of_element_located((By.CLASS_NAME, "target-class")))

# 3. ç­‰å¾… JS å®Œæˆ
wait.until(lambda d: d.execute_script('return document.readyState') == 'complete')
```

### å•é¡Œ 2ï¼šè¢«ç¶²ç«™å°é–

**ç—‡ç‹€**: è¿”å› 403/429 éŒ¯èª¤ï¼Œæˆ–é¡¯ç¤ºé©—è­‰ç¢¼

**è§£æ±ºæ–¹æ¡ˆ**:
```python
# 1. å¢åŠ éš¨æ©Ÿå»¶é²
delay = random.uniform(2.0, 5.0)  # å¢åŠ å»¶é²ç¯„åœ

# 2. é™ä½çˆ¬å–é »ç‡
crawl_interval_minutes = 10  # å¾ 5 åˆ†é˜æ”¹ç‚º 10 åˆ†é˜

# 3. ä½¿ç”¨ undetected-chromedriver (é€²éš)
# pip install undetected-chromedriver
import undetected_chromedriver as uc
driver = uc.Chrome()
```

### å•é¡Œ 3ï¼šé¸æ“‡å™¨å¤±æ•ˆ

**ç—‡ç‹€**: ç¶²ç«™æ”¹ç‰ˆå¾ŒæŠ“ä¸åˆ°è³‡æ–™

**è§£æ±ºæ–¹æ¡ˆ**:
```python
# 1. å¤šå±¤å‚™ç”¨é¸æ“‡å™¨
selectors = ['div.new-class', 'div.old-class', 'article']
for selector in selectors:
    items = soup.select(selector)
    if items:
        break

# 2. ä¿å­˜ debug HTML
with open('debug.html', 'w') as f:
    f.write(html)

# 3. å®šæœŸç›£æ§å‘Šè­¦
if not items:
    send_alert("é¸æ“‡å™¨å¤±æ•ˆï¼Œè«‹æª¢æŸ¥ç¶²ç«™çµæ§‹")
```

### å•é¡Œ 4ï¼šè¨˜æ†¶é«”æ´©æ¼

**ç—‡ç‹€**: é•·æ™‚é–“é‹è¡Œå¾Œè¨˜æ†¶é«”ä¸æ–·å¢åŠ 

**è§£æ±ºæ–¹æ¡ˆ**:
```python
# ç¢ºä¿ driver æ­£ç¢ºé—œé–‰
finally:
    if driver:
        try:
            driver.quit()  # ä½¿ç”¨ quit() è€Œé close()
        except:
            pass
```

---

## åƒè€ƒè³‡æº

- **Selenium å®˜æ–¹æ–‡æª”**: https://www.selenium.dev/documentation/
- **BeautifulSoup æ–‡æª”**: https://www.crummy.com/software/BeautifulSoup/bs4/doc/
- **undetected-chromedriver**: https://github.com/ultrafunkamsterdam/undetected-chromedriver
- **Playwright (æ›¿ä»£æ–¹æ¡ˆ)**: https://playwright.dev/python/

---

## æœ¬å°ˆæ¡ˆç¯„ä¾‹å¯¦ä½œåƒè€ƒ

| æª”æ¡ˆ                          | èªªæ˜                             |
|-------------------------------|----------------------------------|
| `crawler/news_crawler.py`     | ç¯„ä¾‹çˆ¬èŸ²æ ¸å¿ƒ - Trading Economics |
| `crawler/config.py`           | é…ç½®ç®¡ç†                         |
| `crawler/commodity_mapper.py` | è³‡æ–™æ˜ å°„                         |
| `crawler/news_storage.py`     | å„²å­˜å’Œå»é‡                       |
| `crawler/scheduler.py`        | å®šæ™‚ä»»å‹™èª¿åº¦                     |
